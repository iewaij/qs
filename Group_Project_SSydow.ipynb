{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminaries and Imports\n",
    "In the following cell, the necessary packages and libraries are imported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# access to different databases\n",
    "import pandas_datareader as web\n",
    "import quandl as quandl\n",
    "import wrds as wrds\n",
    "\n",
    "# storage and operations\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "# statistics and regression\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.regression.rolling import RollingOLS\n",
    "from scipy.stats.mstats import winsorize\n",
    "\n",
    "# plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.pyplot import figure\n",
    "from matplotlib.axis import Axis\n",
    "import matplotlib.dates as mdates \n",
    "%matplotlib inline\n",
    "\n",
    "# warning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# unzipping zip-files\n",
    "from zipfile import ZipFile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Imports and Preperations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define an useful path\n",
    "path = Path('/Users/sebastiansydow/13_Quant_Trading/Group_Project')\n",
    "# stocks\n",
    "input_stocks = path / 'permno_selection.csv'\n",
    "# link betweeen CRSP (permno) and Option Metrics (SECID)\n",
    "link_permno_secid = path / 'daily_permno_secid_cusip_link.csv.zip'\n",
    "\n",
    "# import stocks from S&P 500 into a pandas dataframe\n",
    "df_input_stocks = pd.read_csv(input_stocks)\n",
    "\n",
    "# instantiate zip-file\n",
    "zip_file = ZipFile(link_permno_secid)\n",
    "# load linking table\n",
    "df_link_permno_secid = pd.read_csv(zip_file.open('daily_permno_secid_cusip_link.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daily Stock Returns, Market Capitalization and Value Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_stock_data(df_input, date_start, date_end, wrds_username):\n",
    "    # Download stock data\n",
    "    ## establish WRDS connection\n",
    "    db = wrds.Connection(wrds_username=wrds_username)\n",
    "    \n",
    "    # create query to load the returns, prices and shares outstanding for S&P 500 companies from 1999/01\n",
    "    sql_wrds = \"\"\"\n",
    "            select distinct date, \n",
    "                            permno,\n",
    "                            cusip, \n",
    "                            ret, \n",
    "                            abs(prc) as prc, \n",
    "                            shrout,\n",
    "                            abs(prc)*shrout/1000 as mktval\n",
    "            from crsp.dsf \n",
    "            where permno in %(permno)s and date>=%(start)s and date<=%(end)s\n",
    "            \"\"\"\n",
    "\n",
    "    # define the parameters, i.e. only those companies (permno), which were part of the S&P 500\n",
    "    # in the timeframe 2000/01 until 2020/12\n",
    "    params = {}\n",
    "    params['start'] = date_start\n",
    "    params['end'] = date_end\n",
    "    params['permno'] = tuple(df_input.permno.unique().astype(str))\n",
    "\n",
    "    # retrieve the data from wrds\n",
    "    df_stock_data = db.raw_sql(sql_wrds, params = params)\n",
    "\n",
    "    # change type of entries in the columns start and ending\n",
    "    df_stock_data['date']  = pd.to_datetime(df_stock_data['date'])\n",
    "    \n",
    "    # shift market_val by 1 day\n",
    "    df_stock_data.loc[:,'mktval_shifted'] = df_stock_data.groupby(['permno'])['mktval'].shift(1)\n",
    "    \n",
    "    # dropna\n",
    "    df_stock_data.dropna(inplace=True)\n",
    "    \n",
    "    # calculate weight of each stock on each day\n",
    "    ## dataframe with total market value on each day\n",
    "    df_ttl_mkcap = df_stock_data[['date', 'mktval_shifted']].groupby('date').sum().rename(columns={\"mktval_shifted\": \"ttl_mktval\"})\n",
    "    ## merge with df_stock_data\n",
    "    df_stock_data = pd.merge(df_stock_data, df_ttl_mkcap, how='left', on=['date'])\n",
    "    ## calculate weightage\n",
    "    df_stock_data['weightage_pct'] =  df_stock_data['mktval_shifted'] / df_stock_data[\"ttl_mktval\"]\n",
    "    ## drop columns\n",
    "    df_stock_data.drop(columns = {'prc', 'shrout', 'mktval', 'mktval_shifted', 'ttl_mktval'}, inplace = True)\n",
    "    \n",
    "    return df_stock_data.sort_values(by=['date']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fama-French-Factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_ffm(date_start, date_end):\n",
    "    # start of time period \n",
    "    startdt = datetime.datetime(int(date_start[:4]),\n",
    "                                int(date_start[5:7]),\n",
    "                                int(date_start[8:]))\n",
    "    \n",
    "    # end of time period                            \n",
    "    enddt = datetime.datetime(int(date_end[:4]),\n",
    "                              int(date_end[5:7]),\n",
    "                              int(date_end[8:]))\n",
    "\n",
    "    # define which dataset are to be downloaded\n",
    "    d1 = web.DataReader('F-F_Research_Data_Factors_daily','famafrench',start=startdt, end=enddt)\n",
    "    d2 = web.DataReader('F-F_Momentum_Factor_daily','famafrench',start=startdt, end=enddt)\n",
    "\n",
    "    # key is 0 -> get returns data\n",
    "    # divide by 100 to get the returns\n",
    "    df_ff_3factor = d1[0]/100\n",
    "\n",
    "    # add momentum factor with an outer-join\n",
    "    # outer-join: keep all data -> union\n",
    "    df_ff_4factor = df_ff_3factor.join(d2[0]/100, how = 'outer')\n",
    "\n",
    "    # reset index for merge later\n",
    "    df_ff_4factor = df_ff_4factor.reset_index()\n",
    "\n",
    "    # change columns to be small letters and get rid of white-spaces\n",
    "    df_ff_4factor.columns = [z.lower().strip() for z in df_ff_4factor.columns]\n",
    "\n",
    "    # rename column\n",
    "    df_ff_4factor.rename(columns = {'mkt-rf':'mktrf'}, inplace = True)\n",
    "\n",
    "    # change order of dataframe\n",
    "    df_ff_4factor = df_ff_4factor.loc[:,['date', 'mktrf', 'smb', 'hml', 'mom', 'rf']]\n",
    "                              \n",
    "    return df_ff_4factor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Excess Return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_excess_return(df, minuend, subtrahend):\n",
    "    # calculate excess return\n",
    "    df['excess_return'] = df[minuend]-df[subtrahend]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perfrom Data Preparation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_prep(df_input, date_start, date_end, df_link, wrds_username, minuend, subtrahend):\n",
    "\n",
    "    ## retrieve data\n",
    "    df_stock_data = retrieve_stock_data(df_input=df_input_stocks, \n",
    "                                        date_start=date_start, \n",
    "                                        date_end=date_end, \n",
    "                                        wrds_username=wrds_username)\n",
    "    \n",
    "    # change type of entries in the columns date\n",
    "    df_link['date']  = pd.to_datetime(df_link['date'])\n",
    "    \n",
    "    ## merge with cusip\n",
    "    df_stock_data = pd.merge(df_stock_data, df_link.loc[:,['permno', 'date', 'secid']], how = \"left\", on = ['permno','date'])\n",
    "    \n",
    "    \n",
    "    # Download Fama-French Factors\n",
    "    df_ffm = download_ffm(date_start=date_start, date_end=date_end)\n",
    "    \n",
    "    ## merge stock data with ffm\n",
    "    # merge with ff-4-factors\n",
    "    df_stocks_ffm = pd.merge(df_stock_data, df_ffm, how='inner', on=['date'])\n",
    "    \n",
    "    # calculate excess return\n",
    "    df_stocks_ffm = calc_excess_return(df=df_stocks_ffm, minuend=minuend, subtrahend=subtrahend)\n",
    "    \n",
    "    return df_stocks_ffm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading library list...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "df_prepared = data_prep(df_input=df_input_stocks,\n",
    "                        date_start='2000-01-01',\n",
    "                        date_end='2019-12-31',\n",
    "                        df_link=df_link_permno_secid,\n",
    "                        wrds_username='sebastiansydow',\n",
    "                        minuend='ret',\n",
    "                        subtrahend='rf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimation of $\\beta$-Factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_betas(df, window_size, period='daily'):\n",
    "    # identify all companies (permnos) in the dataframe\n",
    "    permnos = df.permno.unique()\n",
    "    # loop over all permnos and perform ols regression\n",
    "    for permno in tqdm(range(len(permnos))):\n",
    "        # define dataframe only with current permno\n",
    "        df_current_permno = df[df['permno'] == permnos[permno]]\n",
    "        # only perform OLS for stocks with more than 252 observations\n",
    "        if len(df_current_permno) > window_size:\n",
    "            # dependent variable\n",
    "            Y = df_current_permno['excess_return']\n",
    "            # independent variable\n",
    "            X = df_current_permno[['mktrf', 'smb', 'hml', 'mom']]\n",
    "            # define constant\n",
    "            X_constant = sm.add_constant(X)\n",
    "            # define model\n",
    "            rol_ols_model = RollingOLS(endog=Y, exog=X_constant, window=window_size)\n",
    "            # fitting\n",
    "            # print('Fitting rolling OLS model for permno #', permno, ' from', len(permnos))\n",
    "            results = rol_ols_model.fit()\n",
    "            # parameters\n",
    "            if permno == 0:\n",
    "                df_params = results.params\n",
    "            else:\n",
    "                df_params = pd.concat([df_params, results.params])\n",
    "\n",
    "    # rename columns\n",
    "    df_params.rename(columns = {'mktrf':'beta1', 'smb':'beta2', 'hml':'beta3', 'mom': 'beta4'}, inplace = True)\n",
    "    # merge with df_all by index\n",
    "    print('Merging the dataframes...')\n",
    "    df_betas = pd.merge(df, df_params, how='left', left_index=True, right_index=True, suffixes=[None, None])\n",
    "    # print df_ols\n",
    "    \n",
    "    if period == 'daily':\n",
    "        df_betas.dropna(inplace=True)\n",
    "        df_betas = df_betas.reset_index(drop=True)\n",
    "        return df_betas\n",
    "    \n",
    "    if period == 'monthly':\n",
    "        # create a temporary copy of df_ols\n",
    "        df_temp = df_betas[['permno', 'date', 'const', 'beta1', 'beta2', 'beta3', 'beta4']].copy()\n",
    "\n",
    "        # add necessary columns for group by\n",
    "        df_temp['year'] = df_temp['date'].dt.year\n",
    "        df_temp['month'] = df_temp['date'].dt.month\n",
    "        # group dataframe and select last row \n",
    "        df_temp = df_temp.groupby(['permno','year', 'month']).tail(n=1)\n",
    "        \n",
    "        # rename columns to indicate that those are the betas of the end of each month\n",
    "        df_temp.rename(columns = {'const':'const_eom', 'beta1':'beta1_eom', 'beta2':'beta2_eom', 'beta3':'beta3_eom', 'beta4':'beta4_eom'}, inplace = True)\n",
    "        # merge with df_ols\n",
    "        df_betas_monthly = pd.merge(df_betas, df_temp, how='left', on=['date', 'permno'])\n",
    "        # forward fill estimaed beta factors to assume that they stay constant for the next month until the last day\n",
    "        gb = df_betas_monthly.groupby('permno')\n",
    "        for var in [\"const_eom\", \"beta1_eom\", \"beta2_eom\", \"beta3_eom\", \"beta4_eom\"]:\n",
    "            df_betas_monthly[var] = gb[var].ffill()\n",
    "        \n",
    "        # drop daily betas\n",
    "        df_betas_monthly.drop(columns = {'const', 'beta1', 'beta2', 'beta3', 'beta4', 'year', 'month'}, inplace = True)\n",
    "\n",
    "        # drop nas\n",
    "        df_betas_monthly.dropna(inplace=True)\n",
    "\n",
    "        # reset index of df\n",
    "        df_betas_monthly = df_betas_monthly.reset_index(drop=True)\n",
    "        \n",
    "        return df_betas_monthly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [01:11<00:00,  1.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging the dataframes...\n"
     ]
    }
   ],
   "source": [
    "df_betas = estimate_betas(df=df_prepared, window_size=252, period='monthly')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
